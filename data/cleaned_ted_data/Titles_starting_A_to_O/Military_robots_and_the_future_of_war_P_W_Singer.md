
I thought I&#39;d begin with a scene of war.
There was little to warn of the danger ahead.
The Iraqi insurgent had placed the IED,
an Improvised Explosive Device,
along the side of the road with great care.
By 2006, there were more than 2,500
of these attacks every single month,
and they were the leading cause of
casualties among American soldiers
and Iraqi civilians.
The team that was hunting for this IED
is called an EOD team—
Explosives Ordinance Disposal—and
they&#39;re the pointy end of the spear in the
American effort to suppress these roadside bombs.
Each EOD team goes out on about
600 of these bomb calls every year,
defusing about two bombs a day.
Perhaps the best sign of how valuable they
are to the war effort, is that
the Iraqi insurgents put a $50,000 bounty
on the head of a single EOD soldier.
Unfortunately, this particular call
would not end well.
By the time the soldier advanced close
enough to see the telltale wires
of the bomb, it exploded in a wave of flame.
Now, depending how close you are
and how much explosive has been packed
into that bomb, it can cause death
or injury. You have to be as far as
50 yards away to escape that.
The blast is so strong it can even break
your limbs, even if you&#39;re not hit.
That soldier had been on top of the bomb.
And so when the rest of the team advanced
they found little left. And that night the unit&#39;s
commander did a sad duty, and he wrote
a condolence letter back to the United
States, and he talked about how hard the
loss had been on his unit, about the fact
that they had lost their bravest soldier,
a soldier who had saved their lives
many a time.
And he apologized
for not being able to bring them home.
But then he talked up the silver lining
that he took away from the loss.
&quot;At least,&quot; as he wrote, &quot;when a robot dies,
you don&#39;t have to write a letter
to its mother.&quot;
That scene sounds like science fiction,
but is battlefield reality already.
The soldier in that case
was a 42-pound robot called a PackBot.
The chief&#39;s letter went, not to some
farmhouse in Iowa like you see
in the old war movies, but went to
the iRobot Company, which is
named after the Asimov novel
and the not-so-great Will Smith movie,
and... um... 
(Laughter)
...
if you remember that
in that fictional world, robots started out
carrying out mundane chores, and then
they started taking on life-and-death decisions.
That&#39;s a reality we face today.
What we&#39;re going to do is actually just
flash a series of photos behind me that
show you the reality of robots used in war
right now or already at the prototype stage.
It&#39;s just to give you a taste.
Another way of putting it is you&#39;re not
going to see anything that&#39;s powered
by Vulcan technology, or teenage
wizard hormones or anything like that.
This is all real. So why don&#39;t we
go ahead and start those pictures.
Something big is going on in war today,
and maybe even the history of humanity
itself. The U.S. military went into Iraq with
a handful of drones in the air.
We now have 5,300.
We went in with zero unmanned ground
systems. We now have 12,000.
And the tech term &quot;killer application&quot;
takes on new meaning in this space.
And we need to remember that we&#39;re
talking about the Model T Fords,
the Wright Flyers, compared
to what&#39;s coming soon.
That&#39;s where we&#39;re at right now.
One of the people that I recently met with
was an Air Force three-star general, and he
said basically, where we&#39;re headed very
soon is tens of thousands of robots
operating in our conflicts, and these
numbers matter, because we&#39;re not just
talking about tens of thousands of today&#39;s
robots, but tens of thousands of these
prototypes and tomorrow&#39;s robots, because
of course, one of the things that&#39;s operating
in technology is Moore&#39;s Law,
that you can pack in more and more
computing power into those robots, and so
flash forward around 25 years,
if Moore&#39;s Law holds true,
those robots will be close to a billion times
more powerful in their computing than today.
And so what that means is the kind of
things that we used to only talk about at
science fiction conventions like Comic-Con
have to be talked about in the halls
of power and places like the Pentagon.
A robots revolution is upon us.
Now, I need to be clear here.
I&#39;m not talking about a revolution where you
have to worry about the Governor of
California showing up at your door,
a la the Terminator. 
(Laughter)

When historians look at this period, they&#39;re
going to conclude that we&#39;re in a different

type of revolution: a revolution in war,
like the invention of the atomic bomb.
But it may be even bigger than that,
because our unmanned systems don&#39;t just
affect the &quot;how&quot; of war-fighting,
they affect the &quot;who&quot; of fighting
at its most fundamental level.
That is, every previous revolution in war, be
it the machine gun, be it the atomic bomb,
was about a system that either shot faster,
went further, had a bigger boom.
That&#39;s certainly the case with robotics, but
they also change the experience of the warrior
and even the very identity of the warrior.
Another way of putting this is that
mankind&#39;s 5,000-year-old monopoly
on the fighting of war is breaking down
in our very lifetime. I&#39;ve spent
the last several years going around
meeting with all the players in this field,
from the robot scientists to the science
fiction authors who inspired them to the
19-year-old drone pilots who are fighting
from Nevada, to the four-star generals
who command them, to even the Iraqi
insurgents who they are targeting and what
they think about our systems, and
what I found interesting is not just
their stories, but how their experiences
point to these ripple effects that are going
outwards in our society, in our law
and our ethics, etc. And so what I&#39;d like
to do with my remaining time is basically
flesh out a couple of these.
So the first is that the future of war,
even a robotics one, is not going to be
purely an American one.
The U.S. is currently ahead in military
robotics right now, but we know that in
technology there&#39;s no such thing as
a permanent first move or advantage.
In a quick show of hands, how many
people in this room still use
Wang Computers? 
(Laughter)

It&#39;s the same thing in war. The British and
the French invented the tank.
The Germans figured out how
to use it right, and so what we have to
think about for the U.S. is that we are
ahead right now, but you have
43 other countries out there
working on military robotics, and they
include all the interesting countries like
Russia, China, Pakistan, Iran.
And this raises a bigger worry for me.
How do we move forward in this revolution
given the state of our manufacturing
and the state of our science and
mathematics training in our schools?
Or another way of thinking about this is,
what does it mean to go to war increasingly
with soldiers whose hardware is made
in China and software is written in India?
But just as software has gone open-source,
so has warfare.
Unlike an aircraft carrier or an atomic bomb,
you don&#39;t need a massive manufacturing
system to build robotics. A lot of it is
off the shelf. A lot of it&#39;s even do-it-yourself.
One of those things you just saw flashed
before you was a raven drone, the handheld
tossed one. For about a thousand dollars,
you can build one yourself, equivalent to
what the soldiers use in Iraq.
That raises another wrinkle when it comes
to war and conflict. Good guys might play
around and work on these as hobby kits,
but so might bad guys.
This cross between robotics and things like
terrorism is going to be fascinating
and even disturbing,
and we&#39;ve already seen it start.
During the war between Israel, a state,
and Hezbollah, a non-state actor,
the non-state actor flew
four different drones against Israel.
There&#39;s already a jihadi website
that you can go on and remotely
detonate an IED in Iraq while sitting
at your home computer.
And so I think what we&#39;re going to see is
two trends take place with this.
First is, you&#39;re going to reinforce the power
of individuals against governments,
but then the second is that
we are going to see an expansion
in the realm of terrorism.
The future of it may be a cross between
al Qaeda 2.0 and the
next generation of the Unabomber.
And another way of thinking about this
is the fact that, remember, you don&#39;t have
to convince a robot that they&#39;re gonna
receive 72 virgins after they die
to convince them to blow themselves up.
But the ripple effects of this are going to go
out into our politics. One of the people that
I met with was a former Assistant Secretary of
Defense for Ronald Reagan, and he put it

this way: &quot;I like these systems because
they save American lives, but I worry about
more marketization of wars,
more shock-and-awe talk,
to defray discussion of the costs.
People are more likely to support the use
of force if they view it as costless.&quot;
Robots for me take certain trends
that are already in play in our body politic,
and maybe take them to
their logical ending point.
We don&#39;t have a draft. We don&#39;t
have declarations of war anymore.
We don&#39;t buy war bonds anymore.
And now we have the fact that we&#39;re
converting more and more of our American
soldiers that we would send into harm&#39;s
way into machines, and so we may take
those already lowering bars to war
and drop them to the ground.
But the future of war is also going to be
a YouTube war.
That is, our new technologies don&#39;t merely
remove humans from risk.
They also record everything that they see.

So they don&#39;t just delink the public:
they reshape its relationship with war.
There&#39;s already several thousand
video clips of combat footage from Iraq
on YouTube right now,
most of it gathered by drones.
Now, this could be a good thing.
It could be building connections between
the home front and the war front
as never before.
But remember, this is taking place
in our strange, weird world, and so
inevitably the ability to download these
video clips to, you know, your iPod
or your Zune gives you
the ability to turn it into entertainment.
Soldiers have a name for these clips.
They call it war porn.
The typical one that I was sent was
an email that had an attachment of
video of a Predator strike taking out
an enemy site. Missile hits,
bodies burst into the air with the explosion.
It was set to music.
It was set to the pop song
&quot;I Just Want To Fly&quot; by Sugar Ray.
This ability to watch more
but experience less creates a wrinkle
in the public&#39;s relationship with war.
I think about this with a sports parallel.
It&#39;s like the difference between
watching an NBA game, a professional
basketball game on TV, where the athletes
are tiny figures on the screen, and
being at that basketball game in person
and realizing what someone seven feet
really does look like.
But we have to remember,
these are just the clips.
These are just the ESPN SportsCenter
version of the game. They lose the context.
They lose the strategy.
They lose the humanity. War just
becomes slam dunks and smart bombs.
Now the irony of all this is that
while the future of war may involve
more and more machines,
it&#39;s our human psychology that&#39;s driving
all of this, it&#39;s our human failings
that are leading to these wars.
So one example of this that has
big resonance in the policy realm is
how this plays out on our very real
war of ideas that we&#39;re fighting
against radical groups.
What is the message that we think we are
sending with these machines versus what
is being received in terms of the message.
So one of the people that I met was
a senior Bush Administration official,
who had this to say about

our unmanning of war:
&quot;It plays to our strength. The thing that
scares people is our technology.&quot;
But when you go out and meet with people,
for example in Lebanon, it&#39;s a very
different story. One of the people
I met with there was a news editor, and
we&#39;re talking as a drone is flying above him,
and this is what he had to say.
&quot;This is just another sign of the coldhearted
cruel Israelis and Americans,
who are cowards because
they send out machines to fight us.
They don&#39;t want to fight us like real men,
but they&#39;re afraid to fight,
so we just have to kill a few of their soldiers
to defeat them.&quot;
The future of war also is featuring
a new type of warrior,
and it&#39;s actually redefining the experience
of going to war.
You can call this a cubicle warrior.
This is what one Predator drone pilot
described of his experience fighting
in the Iraq War while never leaving Nevada.
&quot;You&#39;re going to war for 12 hours,
shooting weapons at targets,
directing kills on enemy combatants,
and then you get in the car
and you drive home and within 20 minutes,
you&#39;re sitting at the dinner table
talking to your kids about their homework.&quot;
Now, the psychological balancing
of those experiences is incredibly tough,
and in fact those drone pilots have
higher rates of PTSD than many
of the units physically in Iraq.
But some have worries that this
disconnection will lead to something else,
that it might make the contemplation of war
crimes a lot easier when you have
this distance. &quot;It&#39;s like a video game,&quot;
is what one young pilot described to me
of taking out enemy troops from afar.
As anyone who&#39;s played Grand Theft Auto
knows, we do things in the video world
that we wouldn&#39;t do face to face.
So much of what you&#39;re hearing from me
is that there&#39;s another side
to technologic revolutions,
and that it&#39;s shaping our present
and maybe will shape our future of war.
Moore&#39;s Law is operative,
but so&#39;s Murphy&#39;s Law.
The fog of war isn&#39;t being lifted.
The enemy has a vote.
We&#39;re gaining incredible new capabilities,
but we&#39;re also seeing and experiencing
new human dilemmas. Now,
sometimes these are just &quot;oops&quot; moments,
which is what the head of a robotics
company described it, you just have
&quot;oops&quot; moments. Well, what are
&quot;oops&quot; moments with robots in war?
Well, sometimes they&#39;re funny. Sometimes,
they&#39;re like that scene from the
Eddie Murphy movie &quot;Best Defense,&quot;
playing out in reality, where they tested out
a machine gun-armed robot, and during
the demonstration it started spinning
in a circle and pointed its machine gun
at the reviewing stand of VIPs.
Fortunately the weapon wasn&#39;t loaded
and no one was hurt, but other times
&quot;oops&quot; moments are tragic,
such as last year in South Africa, where
an anti-aircraft cannon had a
&quot;software glitch,&quot; and actually did turn on
and fired, and nine soldiers were killed.
We have new wrinkles in the laws of war
and accountability. What do we do
with things like unmanned slaughter?
What is unmanned slaughter?
We&#39;ve already had three instances of
Predator drone strikes where we thought
we got bin Laden, and it turned out
not to be the case.
And this is where we&#39;re at right now.
This is not even talking about armed,
autonomous systems
with full authority to use force.
And do not believe that that isn&#39;t coming.
During my research I came across
four different Pentagon projects
on different aspects of that.

And so you have this question:
what does this lead to issues like
war crimes? Robots are emotionless, so
they don&#39;t get upset if their buddy is killed.
They don&#39;t commit crimes of rage
and revenge.
But robots are emotionless.
They see an 80-year-old grandmother
in a wheelchair the same way they see

a T-80 tank: they&#39;re both
just a series of zeroes and ones.

And so we have this question to figure out:
How do we catch up our 20th century
laws of war, that are so old right now
that they could qualify for Medicare,
to these 21st century technologies?
And so, in conclusion, I&#39;ve talked about
what seems the future of war,
but notice that I&#39;ve only used
real world examples and you&#39;ve only seen
real world pictures and videos.
And so this sets a great challenge for
all of us that we have to worry about well
before you have to worry about your
Roomba sucking the life away from you.
Are we going to let the fact that what&#39;s
unveiling itself right now in war
sounds like science fiction and therefore
keeps us in denial?
Are we going to face the reality
of 21st century war?
Is our generation going to make the same
mistake that a past generation did
with atomic weaponry, and not deal with
the issues that surround it until
Pandora&#39;s box is already opened up?
Now, I could be wrong on this, and
one Pentagon robot scientist told me
that I was. He said, &quot;There&#39;s no real
social, ethical, moral issues when it comes
to robots.
That is,&quot; he added, &quot;unless the machine
kills the wrong people repeatedly.
Then it&#39;s just a product recall issue.&quot;
And so the ending point for this is
that actually, we can turn to Hollywood.
A few years ago, Hollywood gathered
all the top characters and created
a list of the top 100 heroes and
top 100 villains of all of Hollywood history,
the characters that represented the best
and worst of humanity.

Only one character made it onto both lists:
The Terminator, a robot killing machine.
And so that points to the fact that
our machines can be used
for both good and evil, but for me
it points to the fact that there&#39;s a duality
of humans as well.
This week is a celebration
of our creativity. Our creativity
has taken our species to the stars.
Our creativity has created works of arts
and literature to express our love.
And now, we&#39;re using our creativity
in a certain direction, to build fantastic
machines with incredible capabilities,
maybe even one day
an entirely new species.
But one of the main reasons that we&#39;re
doing that is because of our drive
to destroy each other, and so the question

we all should ask:
is it our machines, or is it us
that&#39;s wired for war?
Thank you. 
(Applause)

