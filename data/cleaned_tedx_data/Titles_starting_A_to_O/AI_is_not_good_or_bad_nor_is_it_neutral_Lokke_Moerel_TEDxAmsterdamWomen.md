
[Music]
recognize this it&#39;s a cookie statement
on the internet if you you have to click
OK before you can actually access a
website or get access to a service who
of you clicks sometimes okay accept all
cookies we all get the t-shirts and I
teach global e-commerce law already for
10 years
I know exactly what cookies do I hate
them they track me across the internet
they collect my data to send me
personalized advertising do I want that
no do I click OK yes so is this a true
expression of my wishes no do we all do
it yes this is what the behavioral
scientists call predictable irrational
behavior irrational because I don&#39;t want
it and still do it and predictable
because we all do it and why is that
it&#39;s because if you what we want to know
what your choices are you have to read
too much stuff to know what you want my
children are on iTunes
there&#39;s terms of end conditions or
nearly 20,000 words Macbeth has less
words
do you think my children read Macbeth
before they click ok there is a great
website out there it&#39;s called Terms of
Service didn&#39;t read and they screen for
us all those 20,000 words to see what
really matters to us is a bit worrisome
if you look at it it says they keep your
data forever they trick you across the
internet and they share your data with
other parties my point is your data is
already out there so that there can be
no misunderstanding about my messages
today I think we&#39;re about to lose
ourselves in a world of data and there
are three reasons the first is we think
we can control who is processing what
data about us for what purposes and our
privacy laws should protect us but they
are based on the assumption that as long
as they inform me about what they&#39;re
going to do with my data for what
purposes that I actually can make an
informed choice well I think the cookie
example shows that that is a lie already
today the second is when artificial
intelligence knows us better than we do
ourselves it can direct us and that
undermines the very premise that we can
make a valid choice third artificial is
not good it&#39;s not bad but it is also not
neutral it&#39;s exactly as good as the data
fed to it and the result is that we have
a lot of artificial intelligence that is
totally biased based on gender or race
simple example if you have a company
with a very similar successful people
are white male and of a certain age and
you feed that data into the algorithm it
will predict that in your job applicant
database it will favor people with
similar profile it&#39;s not only that their
people data scientists who are feeding
the data to the algorithm and it makes a
look
and most of the data scientists at the
moment are white male and of a certain
younger age they are buyers they have
blind spots so we want to remedy that
you actually have to introduce diversity
at the level of the data scientist so if
you introduce new technologies in
society it is intuitively understood
that that has an impact on society but
history tells us that it is impossible
to tell what the effect actually will be
and I&#39;ll give you a simple example very
near to my heart the invention of the
electric iron before that time women
were at home with an actual iron heating
it up on the stove doing the work heavy
work time consuming so what the people
think when this was the new invention
that was easier lighter work and less
time-consuming but what actually
happened was that societal expectations
changed and instead of just the men&#39;s
the colors of the men&#39;s shirt they had
to do the whole shirt plus the
children&#39;s clothes
I know people even ironing the the
sheets I tell you it was lighter work
but there was more of it
so our society is undergoing a
tremendous transformation where
electricity extended our physical powers
ai is now extending our thinking powers
and that results in what scientists call
the sport society the AI analyzes vast
amounts of data already out there they
find correlations people with
characteristics X Y Z are likely to get
obese itas we&#39;re going to be obese now
and then if you look at my
characteristics there&#39;s a prediction
Walker you will be obese and based on
those predictions companies and
governments are going to act you have to
pay your higher health insurance premium
you&#39;re going to offer or you know a
health program so let&#39;s have a look at a
recent example a few weeks ago The
Guardian reported but AI is a better
predictor of your personality based on
Facebook lights may your family and
friends the AI needs 10 likes on
Facebook to outperform your coworker and
300 to outperform your spouse who knows
you of them better than you do yourself
so oh sorry so what is the result of
this our companies and governments doing
something with this we don&#39;t know as I
said the electric garment we don&#39;t know
but there&#39;s countries out there where
being gay is actually a crime is this
tooling going to be used to select it as
border controls so you can&#39;t get in are
you going to be prosecuted when you&#39;re
in the country are you actually getting
a chance to prove you&#39;re not gay do you
see that there&#39;s a shift in the burden
of proof here going on am i having to
prove that I&#39;m not going to be obese you
must have heard about the new book of
Harare he tells us that in 1300 after
Christ we lived in a deal centric
society it was God deciding what was
good what was bad and how you should
live humanism has been telling us now
for a few hundred years that it&#39;s
actually our free will that is the
highest authority of all what now if
algorithms are going to tell us who we
are and what we want we move from a home
of centric environment to a data centric
environment and are we then giving a
given a chance to trump the algorithm or
are we going to be ruled by day
and live in a data dictatorship horace
tells the turning and a lot of
scientists tell us that the turning
point will come if AI knows it&#39;s better
than ourselves and that is actually
nearer by than you think
stanford research finds that the
computers are better judges of our
personality than friends and family and
i just told you about that so what is
the consequence i don&#39;t know think about
the electric car in example I don&#39;t know
but what I do know is that privacy laws
that are based on the assumption that I
can oversee my choices that those
concepts belong to a homo centric world
and are invalid in a data centric world
we need new rules of the road and how
would they look like
I think we need regulators deciding for
us what is allowed and what is not
allowed and do not pass on the hot
potato to individuals who can&#39;t oversee
their choices and I can&#39;t say it better
than Cass Sunstein in his latest book
autonomy of individuals doesn&#39;t require
choices everywhere if people have to
make choices everywhere their autonomy
is actually reduced rather than
increased so how would those new rules
look like I think we have to look at the
rules on unfair advertising we need a
prohibition that of the unfair
processing of personal data is not
allowed and asking consent cannot make
that right consent is no longer fit for
purpose in this age of data thank you
very much
[Applause]
