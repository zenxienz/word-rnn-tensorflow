
[Music]
ten years ago I was giving a talk at an
engineering robotics conference I was
the token lawyer and the talk was on AI
robotics and law and at the end of the
talk of hand goes up in the Q&amp;A and an
engineer stands up and says I don&#39;t
understand why we need all this law
stuff and really he meant all these
lawyers and all we have to do is make
sure that all of our robots and AIS and
all these things are programmed with
Asimov&#39;s Three Laws of Robotics and that
it won&#39;t ask how many people here are
where the Three Laws of Robotics but I
did ask that at this conference and
every hand in the room goes up a robot
may not harm a human being a robot may
not allow harm to come to itself unless
it&#39;s required in order to spare the
human being basic ethical considerations
for robots so all good but the question
that was being asked was why we needed
anything more and at that time there
wasn&#39;t really that much in the way of
actual technologies that were out there
the one could look at and see what their
function was their purpose was how they
operated the risks they pose the
benefits they gained gave us and so in
those circumstances it was going to be
hard to answer that question from the
engineer now fast forward to today and
we&#39;re in a very different situation we
are now actually seeing technologies AAI
technologies move from prototype in the
lab to actual functions and actual
products and society and as we do that
then the questions of law become much
more important and looming and actual
but important to stress it&#39;s because law
can only get actual
the technologies get actual or are very
close to being actual and so we are
reaching that point now nor reaching a
point it&#39;s really quite a marvelous
position to be in in which we now have
enough actual real paths of technology
that we can talk in real ways about the
way in which society should regulate
them and this is an exciting opportunity
the regulation of actual technologies
and in many ways this is going to be
something that enables these
technologies so there are enormous
opportunities here we have to be sure
that we take clear awareness of the
various kinds of risks that are posed
and the harms that are posed but this is
what law regulation and technology have
always done so in the middle of this
exciting conversation we now find that
there&#39;s kind of an extreme and extrusion
from the outside which is that certain
prominent scientists and technologists
are telling us that we yes need to
regulate AI but we need to regulate
artificial intelligence technologies for
a very different reason not for reasons
about the risks posed today or within
the immediately visible path of
technology but because we have to be
worried that at some point in the future
these AI technologies may become
progressively smarter and smarter to the
point that they escape human control
transcend their human programming pose
an existential threat to humanity and
ravages this would be not so important
were we not beginning the conversation
about actual regulation of actual
technology now and I suggest that this
is an extraordinarily bad idea in public
policy and regulation and that it
threatens to hijack this conversation
that we desperately need to have about
actual technologies today
fact I would go one step further and say
that we need to aggressively push back
against this kind of voice at the moment
that the real regulation is most
important you need to push back against
that in large part by just saying these
things are not risks there are
existential risks to humanity nuclear
war possibility of a bio engineered
pathogen that could you know go out and
do terrible terrible things but these
have some basis in actual technologies
even if they haven&#39;t in fact been
realized when we talk about the super
intelligence that&#39;s going to be too
smart for us and ravages we&#39;re talking
about something completely different
that&#39;s in the realm of imagination and I
don&#39;t think that a bare logical
possibility in a possible world as the
philosophers might say constitutes a
risk and it&#39;s certainly not a risk that
analysis of the kind that law regulation
and public policy can or should even
take into account and that&#39;s in large
part because we have plenty of risks
that need to be taken into account for
the technologies that we are actually
seeing emerge now and can foresee very
quickly coming into being but one of the
questions that arises is why does this
happen with AI technologies I mean in
other words why are some of the most
eminent voices in the field
technologists you know great minds in
the field why do they suddenly flip into
this kind of AI apocalypse mode based
around kind of imaginary possibilities
we don&#39;t do this with other technologies
nobody does this with toasters nobody
does it with toasters that are connected
to the Internet of Things well what is
it about AI that winds up eliciting
these kinds of responses and let me just
call this AI enchantment the technology
has this capability of enchanting the
inventors enchanting users and let&#39;s be
clear has the capacity to enchant the
legal regulator type people
lawyers the government regulators judges
and legislators as well and by a chant I
mean that it winds up leading to
distorted perspectives distorted
perceptions and distorted expectations
about what the technology is what its
capabilities and limitations are and
winds up distorting the ways in which we
think about it and this can happen in
two different directions it can distort
us into kind of the dystopian versions
that are preferred by Hollywood the AI
apocalypse apocalyptic AI but it can
also be distorted in the other direction
in the sort of utopian direction into
kind of fantasies that these
technologies will produce a sort of
utopia in which we are all warm and
happy all of our material needs are
solved and we can just devote ourselves
to mindfulness
these are exaggerations of various kinds
and the question is what brings them
about how do they arise now I want to
suggest it&#39;s because AI is special among
technologies in the way in which it
tends to destabilize mental categories
we have that we use to structure our
world and in destabilizing them suddenly
the idea that there are sort of fixed
limits and possibilities winds up
getting all fuzzy up as well and blurred
one of these lines that AI is
particularly addressed to is the
difference between creatures and things
and in destabilizing that line along
with the line of machine execution
execution of its programming on the one
hand and human consciousness
intentionality purpose and will on the
other those lines get blurred which
artificial intelligence almost the very
terminology invites us to do the result
of that can wind up being that we
suddenly have an explosion of mental
possibilities of things that no longer
seem to have limits to us not confined
which can be a great thing until we try
to enact that into law but in this
process of an explosion of possibility
as it leads to exaggerations that push
out to these extremes the AI apocalypse
on the one hand and angelic AI as we
might call the utopian possibility on
the other I think they&#39;re both mistakes
but now particularly the technologists
in the audience are thinking to
themselves yeah but I do not suffer from
sci-fi AI enchantment you know I mean I
stick to my knitting and do stuff I&#39;m
not under this enchantment I want to
suggest however that this is too quick a
conclusion because there are ways in
which you can have a form of AI
enchantment dealing with very ordinary
applications of the technologies that
are in front of us today and are
emerging in the foreseeable paths of
technology now doesn&#39;t require any
sci-fi possibilities there are a number
of ways in which that can arise but the
one I want to pinpoint today is one that
I think is overlooked in part at least
in the world beyond the technologists
themselves and this is the fact that the
language that we use to express human
action turns out to be exactly the same
words we use to describe machine actions
so we say for human beings
she decides to when we say decides in
that case we are talking about decide as
a word that is bound up and connected to
all of human purposiveness she decides
because she has intentions because she
has purpose because she has will we used
the same word when we talk about the
computer deciding to take an action as
it executes its programming
if you and that&#39;s perfectly okay so long
as one bears in mind that we don&#39;t
actually mean quite the same thing and I
don&#39;t know what alternative language
we&#39;d come up with it&#39;s very difficult to
think of a whole new set of words that
would describe what the machine is doing
so we use the same words for both but
insofar as those two get confused
conflated and mixed up it invites very
very distorted perceptions of what the
technology might be now technologists
and my experience are actually very
attentive to this problem and don&#39;t tend
to fall into it but I do not think that
the ordinary world is going to be able
to maintain some strict distance between
these and differentiation and I can
assure you that lawyers government
regulators judges and legislators will
not be able to maintain any kind of
distance like that at least not if they
are not educated and made aware of the
possibilities in order to sort of
separate out what&#39;s machine and what&#39;s
misplaced expectations imported into AI
technologies because we&#39;ve pulled in a
certain set of human concepts now law
has a role to play in just regulation if
you play in society I got a play by
society&#39;s rules but with respect to this
enchantment law can have a role in
helping to disenchant sorry 2d enchant
2d enchant AI and to sort of take down
some of this enchantment that threatens
to distort and give us misperceptions
and it does so primarily by two
mechanisms one is that the law which is
been dealing with new technologies for a
long time looks at AI technologies as
they come online and says we&#39;re gonna
put them into existing legal categories
and the legal categories we have out
there reflect long-standing human
concerns that are not going to go away
human values that we have so safety
there&#39;s one but also
equality and justice and fairness and
these other qualities that are reflected
in categories of law and those are not
going to get tossed out the window on
account of some AI technology but they
have the effect of sort of grounding the
technology and giving it a sense of
limits that are contained within human
purposes the second way in which law can
help be enchant AI is by call it siloing
we will tend to regulate particular a AI
technologies according to the function
they play and the existing laws and the
existing regulations and the existing
regulators soft driving car technologies
will be regulated by the Department of
Transportation the National Highway
Safety Transportation Board
Transportation Safety Board and stuff
related to privacy stuff related to the
use of facial recognition software
predictive analytics and sentencing
behavior for criminals all of these
different kinds of things will tend to
be regulated by whoever deals with that
kind of stuff already and the effect of
that is to break down the kind of
illusion associated the enchantment
associated with artificial intelligence
considered as a single category all by
itself we break it down and discrete and
much more human oriented forms of
technology and regulation now there is
however a risk of course that law itself
can become enchanted and that all these
people that are part of the legal
players legal actors can become
enchanted and I think without concerted
awareness and education become aware
yeah I think they will be enchanted and
they will have very distorted
impressions about what the technology is
what it&#39;s capable of what its
limitations are there are two basic
defenses against this kind of
Enchantment of law one of them
is that simply the people involved in
this have got to be very sophisticated
about the technology itself and I don&#39;t
mean at the level of the computer
scientists and engineers but I do mean
in ways to be able to ask sophisticated
questions that show an awareness of the
distinct areas of AI machine learning
and so on and so on at a level that will
help them to ask the questions about
these things from the standpoint of our
human intended uses of the technology
and that&#39;s the perspective that the
regulator&#39;s should have they have to be
able to translate that into something
that&#39;s concrete the second way in which
we wind up getting past this risk of
enchantment is important because it says
we will de enchant because we will
insist that we treat AI technologies not
as anything which is kind of outside or
beyond human experience or anything even
outside of human beings but that it&#39;s
just another tool like any technology
that human beings have invented ever and
if we see AI technologies as just
another human tool this again will tend
to ground them in the question of how
good are they at carrying out the things
we care about as human beings and to the
extent that law and regulation is able
to make that kind of question concrete
how good is it as a tool then we will be
asking about the effectiveness of that
tool in ways in which it can be bettered
we will not be sitting around worrying
about technology getting AI technology
getting progressively smarter and
smarter and smarter
until it ravages us ravages us so the
question that&#39;s going to arise for EIA I
is never going to be is the technology
too smart
the problem is never going to be that
the technology is too smart it will
always be that it&#39;s too stupid and too
stupid in the sense that it&#39;s a human
tool and that&#39;s what we need it and use
it for that means then that if we don&#39;t
get past the enchantment of AI then we
run the risk of thinking the problem is
that it&#39;s too smart and if we frame it
that way as a question of risks of being
too smart that we must regulate against
then we&#39;re going to wind up producing
bad law for good technology if on the
other hand we get past the AI
enchantment we do get past it then in
that case we will be able to focus on
the question of the AI as a tool which
we can make better and we will
understand them that we can have better
technology through better law thank you
[Applause]
